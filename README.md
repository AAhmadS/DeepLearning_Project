# Multimodal Sentiment Analysis

## Sharif University of Technology <br/> EE Dept. <br/> Deep Learning Course<br/> Dr. E. Fatemizadeh

**Participants**:<br/>
> Ali Abbasi <br/>
> Nima Kelidari <br/>
> Amir Ahmad Shafiee

**Description**:<br/> With the rise of data science methods in almose all important and handy aspects of every-day life, emerges the importance of cross-modal learning methods. This leads to the main idea behind this project. Please see specefic README files for each Phase for detailed information.<br/>


**Supplementary information**:
>**Main-models**: Bert-base uncased, VGG Face<br/>
>**Dataset**: CLIP dataset<br/>
>**Modes**: Text, Image<br/>
>**Final model**: Transformers,<br/>
>**Desc**: During the process, CV methods, NLP methods and a combination of both, implemented first, by a transformers-bsed model, and by the use of weak supervised learning, have been examined and implemented.<br/>

**Tags**:<br/>
* Computer Vision
* NLP
* Bert
* Sentiment Analysis
* Multimodal
* Transformers
* Weak Supervised Learning
* Representation Learning

